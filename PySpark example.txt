# PySpark commands

sc.version

data = spark.read.csv("gs://rs-movielens-1/ratings.csv", header=True, inferSchema=True)

data.show(5)

# Convert your dataframe into an RDD
ratings = data.rdd.map(list)
ratings.take(2)

# Import the Rating object
from pyspark.mllib.recommendation import Rating
# Convert the data into Rating objects
ratings_final = ratings.map(lambda line: Rating(int(line[0]), int(line[1]), float(line[2])));
# This is what a Rating object looks like
ratings_final.take(2)

# Split the data into training and test, in 80-20% ratio
training_data, test_data = ratings_final.randomSplit([0.8,0.2]);

# Import the ALS method
from pyspark.mllib.recommendation import ALS
# Build the model based on the training data, with tank = 10 and iterations = 10
model = ALS.train(training_data, rank=10, iterations=10)

# Drop the ratings column
testdata_no_rating = test_data.map(lambda p: (p[0],p[1]))

# Predict the model  
predictions = model.predictAll(testdata_no_rating)

# Print the first rows of the RDD
predictions.take(2)

# Prepare ratings data
rates = ratings_final.map(lambda r: ((r[0],r[1]),r[2]));
rates.take(1)

# Prepare predictions data
preds = predictions.map(lambda r: ((r[0],r[1]),r[2]))
preds.take(1)

# Join the ratings data with predictions data
rates_and_preds = rates.join(preds)
rates_and_preds.take(1)

# Calculate and print MSE
MSE = rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean()
print("Mean Squared Error of the model for the test data = {:.2f}".format(MSE))


